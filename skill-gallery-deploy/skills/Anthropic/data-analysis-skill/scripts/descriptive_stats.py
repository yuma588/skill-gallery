#!/usr/bin/env python3
"""
æè¿°æ€§ç»Ÿè®¡åˆ†æè„šæœ¬
è®¡ç®—æ•°æ®çš„åŸºæœ¬ç»Ÿè®¡æŒ‡æ ‡
"""

import sys
import json
import pandas as pd
import numpy as np
from pathlib import Path

def load_json(file_path):
    """åŠ è½½JSONåˆ†æç»“æœ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def calculate_statistics(series):
    """
    è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡

    Args:
        series: pandas Series

    Returns:
        dict: ç»Ÿè®¡æŒ‡æ ‡
    """
    stats = {
        'count': int(series.count()),
        'mean': float(series.mean()),
        'std': float(series.std()),
        'min': float(series.min()),
        'max': float(series.max()),
        'median': float(series.median()),
        'q25': float(series.quantile(0.25)),
        'q75': float(series.quantile(0.75)),
        'range': float(series.max() - series.min())
    }

    # è®¡ç®—ä¼—æ•°
    try:
        mode_val = series.mode().iloc[0] if len(series.mode()) > 0 else None
        stats['mode'] = mode_val
    except:
        stats['mode'] = None

    # è®¡ç®—ååº¦å’Œå³°åº¦
    stats['skewness'] = float(series.skew())
    stats['kurtosis'] = float(series.kurtosis())

    # è®¡ç®—å˜å¼‚ç³»æ•°
    if stats['mean'] != 0:
        stats['cv'] = float(stats['std'] / abs(stats['mean']))
    else:
        stats['cv'] = None

    return stats

def analyze_columns(df, columns=None):
    """
    åˆ†ææŒ‡å®šåˆ—

    Args:
        df: DataFrame
        columns: è¦åˆ†æçš„åˆ—ååˆ—è¡¨

    Returns:
        dict: åˆ†æç»“æœ
    """
    if columns is None:
        # åˆ†ææ‰€æœ‰æ•°å€¼åˆ—
        columns = df.select_dtypes(include=[np.number]).columns.tolist()

    results = {}
    for col in columns:
        if col in df.columns:
            try:
                series = pd.to_numeric(df[col], errors='coerce')
                stats = calculate_statistics(series.dropna())
                results[col] = stats
            except Exception as e:
                print(f"è­¦å‘Š: åˆ— '{col}' åˆ†æå¤±è´¥ - {e}")

    return results

def generate_summary(stats):
    """
    ç”Ÿæˆç»Ÿè®¡æ‘˜è¦

    Args:
        stats: ç»Ÿè®¡ç»“æœå­—å…¸

    Returns:
        dict: æ‘˜è¦ä¿¡æ¯
    """
    summary = {
        'total_columns': len(stats),
        'high_cv_columns': [],
        'high_skewness_columns': [],
        'high_kurtosis_columns': []
    }

    for col, col_stats in stats.items():
        # é«˜å˜å¼‚ç³»æ•° (> 0.3)
        if col_stats.get('cv') and col_stats['cv'] > 0.3:
            summary['high_cv_columns'].append({
                'column': col,
                'cv': col_stats['cv']
            })

        # é«˜ååº¦ (> 1 æˆ– < -1)
        if abs(col_stats['skewness']) > 1:
            summary['high_skewness_columns'].append({
                'column': col,
                'skewness': col_stats['skewness']
            })

        # é«˜å³°åº¦ (> 3 æˆ– < -3)
        if abs(col_stats['kurtosis']) > 3:
            summary['high_kurtosis_columns'].append({
                'column': col,
                'kurtosis': col_stats['kurtosis']
            })

    return summary

def save_json(data, output_path):
    """ä¿å­˜JSONç»“æœ"""
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=str)

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    input_path = sys.argv[1] if len(sys.argv) > 1 else 'analysis_result.json'
    output_path = sys.argv[2] if len(sys.argv) > 2 else 'descriptive_stats.json'
    columns = None

    # è§£æå‚æ•°
    i = 3
    while i < len(sys.argv):
        if sys.argv[i] == '--columns' and i + 1 < len(sys.argv):
            columns = sys.argv[i + 1].split(',')
            i += 2
        else:
            i += 1

    print(f"ğŸ“Š æè¿°æ€§ç»Ÿè®¡åˆ†æ")
    print(f"   è¾“å…¥: {input_path}")

    # åŠ è½½åˆ†æç»“æœ
    data = load_json(input_path)

    # ä»åŸå§‹æ•°æ®é‡å»ºDataFrame
    sample_data = data.get('sample_data', [])
    if sample_data:
        df = pd.DataFrame(sample_data)
    else:
        print("é”™è¯¯: æ— æ³•è·å–æ•°æ®æ ·æœ¬")
        sys.exit(1)

    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")

    # é€‰æ‹©è¦åˆ†æçš„åˆ—
    if columns:
        # è¿‡æ»¤åªå­˜åœ¨çš„åˆ—
        columns = [col for col in columns if col in df.columns]
        print(f"âœ“ åˆ†æåˆ—: {', '.join(columns)}")
    else:
        columns = df.select_dtypes(include=[np.number]).columns.tolist()
        print(f"âœ“ è‡ªåŠ¨æ£€æµ‹åˆ° {len(columns)} ä¸ªæ•°å€¼åˆ—")

    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    stats = analyze_columns(df, columns)
    print(f"âœ“ ç»Ÿè®¡æŒ‡æ ‡è®¡ç®—å®Œæˆ")

    # ç”Ÿæˆæ‘˜è¦
    summary = generate_summary(stats)

    # ç»„è£…ç»“æœ
    result = {
        'timestamp': pd.Timestamp.now().isoformat(),
        'statistics': stats,
        'summary': summary
    }

    # ä¿å­˜ç»“æœ
    save_json(result, output_path)
    print(f"âœ“ ç»“æœå·²ä¿å­˜: {output_path}")

    # æ‰“å°æ‘˜è¦
    print(f"\nç»Ÿè®¡æ‘˜è¦:")
    print(f"  - åˆ†æåˆ—æ•°: {summary['total_columns']}")
    print(f"  - é«˜å˜å¼‚ç³»æ•°åˆ—: {len(summary['high_cv_columns'])}")
    print(f"  - é«˜ååº¦åˆ—: {len(summary['high_skewness_columns'])}")
    print(f"  - é«˜å³°åº¦åˆ—: {len(summary['high_kurtosis_columns'])}")

if __name__ == '__main__':
    main()
