#!/usr/bin/env python3
"""
Excelæ•°æ®åˆ†æè„šæœ¬
è¯»å–Excelæ–‡ä»¶å¹¶è¿›è¡ŒåŸºç¡€æ•°æ®é¢„å¤„ç†
"""

import sys
import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime

def load_excel(file_path, sheet_name=None):
    """
    åŠ è½½Excelæ–‡ä»¶

    Args:
        file_path: Excelæ–‡ä»¶è·¯å¾„
        sheet_name: å·¥ä½œè¡¨åç§°ï¼ˆå¯é€‰ï¼‰

    Returns:
        DataFrame: åŠ è½½çš„æ•°æ®
    """
    try:
        if sheet_name:
            df = pd.read_excel(file_path, sheet_name=sheet_name)
        else:
            df = pd.read_excel(file_path)
        return df
    except Exception as e:
        print(f"é”™è¯¯: è¯»å–Excelæ–‡ä»¶å¤±è´¥ - {e}")
        sys.exit(1)

def clean_data(df):
    """
    æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†

    Args:
        df: åŸå§‹DataFrame

    Returns:
        DataFrame: æ¸…æ´—åçš„æ•°æ®
    """
    # å¤„ç†ç¼ºå¤±å€¼
    df_cleaned = df.copy()

    # æ•°å€¼åˆ—ï¼šå¡«å……ä¸­ä½æ•°
    numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if df_cleaned[col].isnull().sum() > 0:
            median_val = df_cleaned[col].median()
            df_cleaned[col].fillna(median_val, inplace=True)

    # å­—ç¬¦åˆ—ï¼šå¡«å……"æ— æ•°æ®"
    string_cols = df_cleaned.select_dtypes(include=['object']).columns
    for col in string_cols:
        if df_cleaned[col].isnull().sum() > 0:
            df_cleaned[col].fillna('æ— æ•°æ®', inplace=True)

    # å°è¯•è½¬æ¢æ—¥æœŸåˆ—
    for col in df_cleaned.columns:
        col_lower = str(col).lower()
        if 'date' in col_lower or 'æ—¥æœŸ' in col_lower or 'æ—¶é—´' in col_lower:
            try:
                df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')
            except:
                pass

    return df_cleaned

def analyze_data_structure(df):
    """
    åˆ†ææ•°æ®ç»“æ„

    Args:
        df: DataFrame

    Returns:
        dict: æ•°æ®ç»“æ„ä¿¡æ¯
    """
    structure = {
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'column_names': list(df.columns),
        'data_types': {col: str(dtype) for col, dtype in df.dtypes.items()},
        'missing_values': {col: int(df[col].isnull().sum()) for col in df.columns},
        'memory_usage': float(df.memory_usage(deep=True).sum() / 1024)
    }

    return structure

def identify_column_types(df):
    """
    è¯†åˆ«åˆ—çš„ç±»å‹ï¼ˆæ•°å€¼ã€æ—¥æœŸã€åˆ†ç±»ï¼‰

    Args:
        df: DataFrame

    Returns:
        dict: åˆ—ç±»å‹åˆ†ç±»
    """
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    date_cols = df.select_dtypes(include=['datetime64']).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

    return {
        'numeric': numeric_cols,
        'date': date_cols,
        'categorical': categorical_cols
    }

def save_json(data, output_path):
    """
    ä¿å­˜åˆ†æç»“æœä¸ºJSON

    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2, default=str)

def main():
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    file_path = sys.argv[1] if len(sys.argv) > 1 else None
    output_path = sys.argv[2] if len(sys.argv) > 2 else 'analysis_result.json'
    sheet_name = None

    # è§£æå‚æ•°
    i = 3
    while i < len(sys.argv):
        if sys.argv[i] == '--sheet' and i + 1 < len(sys.argv):
            sheet_name = sys.argv[i + 1]
            i += 2
        else:
            i += 1

    if not file_path:
        print("é”™è¯¯: è¯·æŒ‡å®šExcelæ–‡ä»¶è·¯å¾„")
        print("ç”¨æ³•: python analyze_excel.py <file> [--sheet <name>] [--output <output>]")
        sys.exit(1)

    print(f"ğŸ“Š åˆ†ææ–‡ä»¶: {file_path}")

    # åŠ è½½æ•°æ®
    df = load_excel(file_path, sheet_name)
    print(f"âœ“ åŠ è½½å®Œæˆ: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")

    # æ•°æ®æ¸…æ´—
    df_cleaned = clean_data(df)
    print("âœ“ æ•°æ®æ¸…æ´—å®Œæˆ")

    # åˆ†ææ•°æ®ç»“æ„
    structure = analyze_data_structure(df_cleaned)

    # è¯†åˆ«åˆ—ç±»å‹
    column_types = identify_column_types(df_cleaned)

    # ä¿å­˜æ•°æ®æ ·æœ¬
    sample_data = df_cleaned.head(10).to_dict('records')

    # ç»„è£…ç»“æœ
    result = {
        'file_path': file_path,
        'timestamp': datetime.now().isoformat(),
        'structure': structure,
        'column_types': column_types,
        'sample_data': sample_data
    }

    # ä¿å­˜ç»“æœ
    save_json(result, output_path)
    print(f"âœ“ ç»“æœå·²ä¿å­˜: {output_path}")
    print(f"\næ•°æ®æ¦‚è¦:")
    print(f"  - æ€»è¡Œæ•°: {structure['total_rows']}")
    print(f"  - æ€»åˆ—æ•°: {structure['total_columns']}")
    print(f"  - æ•°å€¼åˆ—: {len(column_types['numeric'])}")
    print(f"  - æ—¥æœŸåˆ—: {len(column_types['date'])}")
    print(f"  - åˆ†ç±»åˆ—: {len(column_types['categorical'])}")
    print(f"  - å†…å­˜å ç”¨: {structure['memory_usage']:.2f} KB")

if __name__ == '__main__':
    main()
